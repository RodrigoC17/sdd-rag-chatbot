# RAG Chatbot â€“ Obligatorio 2

Este proyecto fue desarrollado como parte del curso **Sistemas de Soporte de DecisiÃ³n** en la **Universidad ORT Uruguay**.

Combina un backend en **FastAPI** con un frontend en **React + Vite**, e implementa un chatbot con recuperaciÃ³n aumentada por generaciÃ³n (**RAG**) utilizando **LangChain** y **Ollama**.

---

## ğŸš€ Requisitos

- Python 3.10+
- Node.js 18+
- Ollama instalado localmente con los modelos:
  - `nomic-embed-text`
  - `deepseek-r1:1.5b`

---

## â–¶ï¸ CÃ³mo ejecutar

### Backend

```bash
cd backend
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
uvicorn app:app --reload
```

### Frontend

```bash
cd frontend
npm install
```

Crear un archivo `.env` con:

```env
VITE_BACKEND_URL=http://localhost:8000
```

Luego ejecutar:

```bash
npm run dev
```

---

## ğŸ“ Estructura

- `backend/` â€“ API FastAPI y lÃ³gica de procesamiento de PDFs
- `frontend/` â€“ Interfaz web en React

---

## âš ï¸ Nota

Si Ollama se ejecuta en un puerto distinto al predeterminado (`11434`), se puede indicar mediante:

```bash
set OLLAMA_HOST=http://localhost:<PUERTO>
```

---

## ğŸ‘¤ Autor

**Rodrigo Calleros**  
Estudiante de Licenciatura en Sistemas â€“ Universidad ORT Uruguay
